job.name=WriterJob

job.master=local[2]

key.avro.schema=src\\test\\resources\\example_key_schema.avsc
payload.avro.schema=src\\test\\resources\\example_payload_schema.avsc

avro.record.name=RecordName

avro.record.namespace=RecordNamespace

log.level=INFO

test.data.entries=10

parquet.data.source=some_parquet_file

parquet.data.source.column=errCol

# number of partitions to paralellize the data before writing
num.partitions=1

# if true, schema will be inferred from Dataframe, otherwise the value set to avro.schema will be used
infer.schema=true

# if true, the application will keep running in a loop, otherwise it will execute just once
execution.repeat=false

schema.registry.url=http://your_schema_registry:8081

### OPTIONS ###
#Properties starting with 'option.' will be set into streams readers and writers

option.kafka.bootstrap.servers=localhost:9092

option.topic=test_topic

# security options (comment in case the Kafka cluster is not secured)
option.kafka.security.protocol=SSL
option.kafka.ssl.truststore.location=path\to\your\truststore.jks
option.kafka.ssl.truststore.password=your_truststore_password
option.kafka.ssl.keystore.location=path\to\your\keystore.jks
option.kafka.ssl.keystore.password=your_keystore_password
option.kafka.ssl.key.password=your_ssl_password

