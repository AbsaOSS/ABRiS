job.name=WriterJob

job.master=local[2]

avro.schema=src\\test\\resources\\example_schema.avsc

avro.record.name=RecordName

avro.record.namespace=RecordNamespace

log.level=INFO

test.data.entries=10

parquet.data.source=some_parquet_file

parquet.data.source.column=errCol

# number of partitions to paralellize the data before writing
num.partitions=1

# if true, schema will be inferred from Dataframe, otherwise the value set to avro.schema will be used
infer.schema=false

# if true, the application will keep running in a loop, otherwise it will execute just once
execution.repeat=false

schema.registry.url=http://jgodsr000000260:8081

### OPTIONS ###
#Properties starting with 'option.' will be set into streams readers and writers

option.kafka.bootstrap.servers=JGODSR000000243:9092,JGODSR000000244:9092,JGODSR000000245:9092

option.topic=prague_test_topic_1

# security options (comment in case the Kafka cluster is not secured)
option.kafka.security.protocol=SSL
option.kafka.ssl.truststore.location=F:\\KafkaAvro\\kafka.melofeli.truststore.jks
option.kafka.ssl.truststore.password=melofeli@123
option.kafka.ssl.keystore.location=F:\\KafkaAvro\\kafka.melofeli.keystore.jks
option.kafka.ssl.keystore.password=melofeli@123
option.kafka.ssl.key.password=melofeli@123

