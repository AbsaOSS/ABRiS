job.name=WriterJob

job.master=local[2]

key.avro.schema=src/test/resources/example_key_schema.avsc
payload.avro.schema=src/test/resources/example_payload_schema.avsc

avro.key.record.name=RecordName
avro.key.record.namespace=RecordNamespace
avro.value.record.name=RecordName
avro.value.record.namespace=RecordNamespace

log.level=INFO

test.data.entries=5

parquet.data.source=some_parquet_file

parquet.data.source.column=errCol

# number of partitions to paralellize the data before writing
num.partitions=1

# if true, schema will be inferred from Dataframe, otherwise the value set to avro.schema will be used
infer.schema=false

# used only for vanilla avro, confluent avro is always using registry
example.should.use.schema.registry=true

# if true, the application will keep running in a loop, otherwise it will execute just once
execution.repeat=false

schema.registry.url=http://localhost:8081

### OPTIONS ###
#Properties starting with 'option.' will be set into streams readers and writers

option.kafka.bootstrap.servers=PLAINTEXT://localhost:9092

option.topic=test_topic

key.schema.naming.strategy=topic.name

value.schema.naming.strategy=topic.record.name

# security options (comment in case the Kafka cluster is not secured)
#option.kafka.security.protocol=SSL
#option.kafka.ssl.truststore.location=path/to/your/truststore.jks
#option.kafka.ssl.truststore.password=your_truststore_password
#option.kafka.ssl.keystore.location=path/to/your/keystore.jks
#option.kafka.ssl.keystore.password=your_keystore_password
#option.kafka.ssl.key.password=your_ssl_password

