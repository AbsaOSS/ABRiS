job.name=WriterJob

job.master=local[2]

avro.schema=src\\test\\resources\\example_schema.avsc

avro.record.name=RecordName

avro.record.namespace=RecordNamespace

log.level=INFO

test.data.entries=10

parquet.data.source=some_parquet_file

parquet.data.source.column=errCol

# number of partitions to paralellize the data before writing
num.partitions=1

# if true, schema will be inferred from Dataframe, otherwise the value set to avro.schema will be used
infer.schema=false

# if true, the application will keep running in a loop, otherwise it will execute just once
execution.repeat=false


### OPTIONS ###
#Properties starting with 'option.' will be set into streams readers and writers

option.kafka.bootstrap.servers=localhost:9092

option.topic=example_schema_topic

# security options (comment in case the Kafka cluster is not secured)
option.kafka.security.protocol=SSL
option.kafka.ssl.truststore.location=keystore/kafka.your.truststore.jks
option.kafka.ssl.truststore.password=your_truststore_pass
option.kafka.ssl.keystore.location=keystore/kafka.your.keystore.jks
option.kafka.ssl.keystore.password=your_keystore_pass
option.kafka.ssl.key.password=you_ssl_pass

